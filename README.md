# FINAM Forecast

Проект для прогнозирования цен акций с использованием данных свечей и новостей. Решение использует машинное обучение (LightGBM) для предсказания будущих цен на основе исторических данных и анализа новостей.

## Описание проекта

Проект состоит из нескольких этапов:
1. **Извлечение признаков из новостей** - анализ новостей с помощью LLM для получения sentiment, важности, категории и затронутых тикеров
2. **Объединение данных** - создание единого датасета из свечей и новостей с учетом временных лагов
3. **Обучение моделей** - тренировка отдельных моделей LightGBM для каждого тикера
4. **Генерация прогнозов** - создание submission файла с предсказаниями на будущие даты

## Структура проекта

```
FINAM_FORECAST/
├── data/                          # Директория с данными (создается автоматически)
│   ├── candles.csv               # Исторические данные свечей (загрузить)
│   ├── news.csv                  # Новости (загрузить)
│   ├── train_news_features.csv   # Извлеченные признаки новостей (создается)
│   ├── combined_dataset.csv      # Объединенный датасет (создается)
│   └── submission.csv            # Файл с прогнозами (создается)
├── scripts/                      # Скрипты проекта
│   ├── config.py                 # Конфигурация и пути
│   ├── news_classification.py    # Извлечение признаков из новостей
│   ├── dataset.py                # Объединение данных
│   ├── train_models.py           # Обучение моделей
│   └── make_submission.py        # Генерация прогнозов
├── ticker_models/                # Сохраненные модели (создается)
├── pyproject.toml                # Зависимости Poetry
└── README.md                     # Документация
```

## Необходимые данные

**ВАЖНО**: Перед запуском проекта необходимо предварительно загрузить следующие файлы в директорию `data/`:

### candles.csv
Файл с историческими данными свечей. Должен содержать колонки:
- `open` - цена открытия
- `close` - цена закрытия  
- `high` - максимальная цена
- `low` - минимальная цена
- `volume` - объем торгов
- `begin` - дата и время (формат: YYYY-MM-DD HH:MM:SS)
- `ticker` - символ тикера

### news.csv
Файл с новостями. Должен содержать колонки:
- `publish_date` - дата публикации (формат: YYYY-MM-DD HH:MM:SS)
- `text` - текст новости
- `ticker` - символ тикера (может быть пустым)

## Установка и запуск

### 1. Установка зависимостей

```bash
# Установка Poetry (если не установлен)
curl -sSL https://install.python-poetry.org | python3 -

# Установка зависимостей проекта
poetry install --no-root
```

### 2. Настройка API ключа

Отредактируйте файл `scripts/config.py` и укажите ваш API ключ для OpenRouter:

```python
OPENROUTER_API_KEY = "ваш_api_ключ"
```

**Примечание**: Проект использует модель `openai/gpt-4o-mini` через OpenRouter API для анализа новостей. Это оптимальный баланс между скоростью и точностью извлечения признаков.

### 3. Запуск решения

Выполните команды в следующем порядке:

```bash
cd scripts

# 1. Извлечение признаков из новостей
poetry run python news_classification.py

# 2. Создание объединенного датасета
poetry run python dataset.py

# 3. Обучение моделей
poetry run python train_models.py

# 4. Генерация прогнозов
poetry run python make_submission.py
```

## Описание файлов

### config.py
Центральный файл конфигурации, содержащий:
- Пути к файлам данных
- Параметры модели (лаги, окна, количество дней прогноза)
- Настройки API для OpenRouter
- Фиксированный seed для воспроизводимости

### news_classification.py
Извлекает признаки из новостей с помощью LLM (модель: **openai/gpt-4o-mini**):

**Извлекаемые признаки:**
- **sentiment** - тональность новости (от -1 до 1, где -1 = негативная, 0 = нейтральная, 1 = позитивная)
- **importance** - важность новости (от 1 до 10, где 10 = критически важная)
- **category** - категория новости (например: "earnings", "merger", "regulatory", "market_analysis")
- **affected_tickers** - список затронутых тикеров (массив символов акций)

**Особенности:**
- Использует асинхронные запросы для ускорения обработки (до 100 параллельных запросов)
- Автоматические повторы при ошибках API
- Обработка больших объемов новостей с прогресс-баром

### dataset.py
Объединяет данные свечей и новостей:
- Создает технические индикаторы (лаги, скользящие средние)
- Агрегирует новости по дате и тикеру
- Применяет one-hot encoding для категорий новостей
- Учитывает временной лаг: новости сдвигаются на 1 день назад (новости пишутся через день после изменений)

### train_models.py
Обучает модели LightGBM для каждого тикера:
- Использует RandomizedSearchCV для подбора гиперпараметров
- Применяет TimeSeriesSplit для кросс-валидации
- Поддерживает GPU ускорение (если доступно)
- Сохраняет модели и информацию о признаках

### make_submission.py
Генерирует прогнозы на будущие даты:
- Создает будущие даты для прогнозирования
- Заполняет отсутствующие признаки нулями
- Загружает обученные модели
- Создает submission файл с прогнозами

## Параметры модели

Основные параметры можно настроить в `config.py`:

- `TARGET_DAYS = 20` - количество дней для прогнозирования
- `LAGS = [1, 2, 3, 5, 10]` - лаги для технических индикаторов
- `WINDOWS = [3, 5, 10]` - окна для скользящих средних
- `SEED = 42` - фиксированный seed для воспроизводимости

## Особенности

- **Временные лаги**: Новости сдвигаются на 1 день назад для корректного прогнозирования
- **GPU поддержка**: Автоматическое определение и использование GPU для LightGBM
- **Воспроизводимость**: Фиксированный seed во всех компонентах
- **Асинхронность**: Быстрая обработка новостей с помощью параллельных запросов
- **Масштабируемость**: Отдельные модели для каждого тикера

## Требования

- Python 3.12
- Poetry для управления зависимостями
- API ключ OpenRouter для анализа новостей
- GPU (опционально) для ускорения обучения моделей

## Результат

После выполнения всех этапов в файле `data/submission.csv` будут содержаться прогнозы цен на заданное количество дней вперед для всех тикеров из исходных данных.
